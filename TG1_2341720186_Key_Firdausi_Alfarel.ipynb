{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "BWVJovQYABCS"
      ],
      "authorship_tag": "ABX9TyMKC/oLCSbiOVnAervTD13B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keyfarel/AI-Ganjil-2025/blob/main/TG1_2341720186_Key_Firdausi_Alfarel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tugas Praktikum 1**"
      ],
      "metadata": {
        "id": "uHrCufk7AAkn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Instalasi Library**"
      ],
      "metadata": {
        "id": "BWVJovQYABCS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEtmuRW79dP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f6e8089-26f0-4884-a36c-e811eb965e89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPREP\n",
            "  Downloading pyprep-0.5.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.21.1)\n",
            "Collecting pyECG\n",
            "  Downloading pyECG-0.0.9.1-py2.py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting mne>=1.3.0 (from PyPREP)\n",
            "  Downloading mne-1.10.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.20.2 in /usr/local/lib/python3.12/dist-packages (from PyPREP) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.12/dist-packages (from PyPREP) (5.9.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.35.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Collecting ishneholterlib==2017.4.11 (from pyECG)\n",
            "  Downloading ishneholterlib-2017.4.11.tar.gz (7.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wfdb==2.2.1 (from pyECG)\n",
            "  Downloading wfdb-2.2.1.tar.gz (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m770.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from pyECG) (8.4.1)\n",
            "Collecting pytest-cov (from pyECG)\n",
            "  Downloading pytest_cov-6.2.1-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting PyCRC (from ishneholterlib==2017.4.11->pyECG)\n",
            "  Downloading pycrc-0.11.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting nose>=1.3.7 (from wfdb==2.2.1->pyECG)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.12/dist-packages (from wfdb==2.2.1->pyECG) (3.10.0)\n",
            "Requirement already satisfied: pandas>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from wfdb==2.2.1->pyECG) (2.2.2)\n",
            "Collecting sklearn>=0.0 (from wfdb==2.2.1->pyECG)\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPREP scipy wandb pyECG"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bagian 1: Penjelasan Library**\n",
        "\n",
        "### **1. PyPREP**\n",
        "> **PyPREP** merupakan implementasi Python dari *PREP pipeline*, yaitu metode *automated preprocessing* untuk sinyal EEG.  \n",
        "> Library ini digunakan untuk mendeteksi dan memperbaiki *bad channels*, melakukan *line noise removal*, serta menormalkan sinyal EEG.  \n",
        "> Dengan PyPREP, proses praproses data EEG dapat dilakukan secara lebih konsisten dan efisien dibandingkan pengolahan manual.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **2. SciPy**\n",
        "> **SciPy** adalah library *open-source* untuk komputasi ilmiah (*scientific computing*).  \n",
        "> Library ini menyediakan berbagai fungsi matematis tingkat lanjut, termasuk *linear algebra*, optimisasi, transformasi Fourier, pemrosesan sinyal, dan statistik.  \n",
        "> Dalam penelitian dan pengembangan berbasis data, SciPy berperan sebagai fondasi analisis dan perhitungan numerik yang kompleks.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **3. Weights & Biases (wandb)**\n",
        "> **Weights & Biases (wandb)** adalah platform untuk *experiment tracking*, *model management*, dan visualisasi hasil pelatihan model *machine learning*.  \n",
        "> Dengan wandb, peneliti dapat memonitor parameter eksperimen, mengelola versi model, dan melakukan kolaborasi tim.  \n",
        "> Penggunaan wandb memperkuat *reproducibility* dalam riset dan pengembangan AI.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **4. pyECG**\n",
        "> **pyECG** adalah library yang berfokus pada analisis sinyal elektrokardiogram (ECG).  \n",
        "> Library ini menyediakan fungsi untuk *preprocessing*, ekstraksi fitur, hingga analisis *heart rate variability*.  \n",
        "> pyECG mempermudah proses analisis medis berbasis data, khususnya untuk penelitian kardiovaskular."
      ],
      "metadata": {
        "id": "PmWoL0s9AOYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bagian 2: Analisis Etika, Hukum, dan Dampak Lingkungan**\n",
        "\n",
        "### **1. Contoh Tindakan yang Melanggar Etika dan Hukum dalam Penggunaan Kecerdasan Buatan**\n",
        "> Penggunaan kecerdasan buatan (AI) memiliki potensi besar, namun penyalahgunaannya dapat menimbulkan pelanggaran etika dan hukum. Salah satu contohnya adalah **deepfake** yang digunakan untuk penyebaran disinformasi atau pencemaran nama baik. Deepfake memanfaatkan teknologi AI untuk memanipulasi gambar atau video sehingga tampak realistis, yang sering kali merugikan individu atau organisasi.  \n",
        ">\n",
        "> Contoh lain adalah **penggunaan AI untuk pengawasan massal tanpa izin**, yang dapat melanggar hak privasi dan bertentangan dengan regulasi seperti *General Data Protection Regulation (GDPR)* di Uni Eropa. Kasus-kasus ini menyoroti pentingnya kebijakan dan regulasi dalam penerapan teknologi AI.<br><br>\n",
        ">\n",
        "> **Referensi:**\n",
        "> - [The Emergence of Deepfake Technology: A Review](https://timreview.ca/article/1282)\n",
        "\n",
        "<br>\n",
        "\n",
        "## **2. Dampak Energi dan Lingkungan dari Pemanfaatan Kecerdasan Buatan**\n",
        "> Pengembangan model AI berskala besar, seperti *Large Language Models (LLM)*, memerlukan sumber daya komputasi yang signifikan. Hal ini berdampak pada:\n",
        "> - **Konsumsi Energi Tinggi:** Pelatihan model AI membutuhkan daya komputasi besar, mengakibatkan penggunaan listrik tinggi.\n",
        "> - **Jejak Karbon yang Besar:** Data center yang menjalankan model AI menghasilkan emisi karbon signifikan, yang berkontribusi pada perubahan iklim.<br><br>\n",
        ">\n",
        "> **Cara Mengatasi (Pendapat Pribadi):**\n",
        "> 1. Optimalisasi algoritma dan arsitektur model untuk mengurangi kompleksitas komputasi.  \n",
        "> 2. Pemanfaatan *green energy* pada pusat data untuk mengurangi emisi karbon.  \n",
        "> 3. Penggunaan teknik seperti *model distillation* dan *transfer learning* agar pelatihan model lebih hemat sumber daya.  \n",
        "> 4. Pengembangan kebijakan keberlanjutan dalam riset AI oleh institusi akademik dan industri.<br><br>\n",
        ">\n",
        "> **Referensi:**\n",
        "> - [Energy and Policy Considerations for Deep Learning in NLP](https://aclanthology.org/P19-1355/)  \n",
        "> - [Carbon Emissions and Large Neural Network Training](https://arxiv.org/abs/2104.10350)  "
      ],
      "metadata": {
        "id": "R6dKd2xtyiyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tugas Pendahuluan"
      ],
      "metadata": {
        "id": "j0B3W_jqIRMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Link Spreadsheet:\n",
        "\n",
        "> [Dataset Mahasiswa TI-3D](https://docs.google.com/spreadsheets/d/1U2Y5gE0U-VNQICMmBGQv0SaTQxXmtZBxvC-T4Hf_a5Q/edit?usp=sharing)"
      ],
      "metadata": {
        "id": "A1EknCSuIZt6"
      }
    }
  ]
}